HTreeMap
========

HTreeMap (provides HashMap and HashSet) is one of ``Map``'s offered by MapDB. It has
great performance with large keys. It also offers entry expiration based on size or time-to-live

HTreeMap is *segmented Hash Tree*. Most hash collections use hash table based in fixed size array, 
when it becomes full, all data has to be moved and rehashed into 
new bigger table. HTreeMap uses auto-expandind Hash Treestructure, so it never needs resizing. 
It also occupies less space, since empty hash slots do not consume any space.
On other side tree structure requries more seeks and is slower on access. 
Its performance degrades with size, but maximal has dir node size is 255,
so degradation is very small. 
TODO performance degradation depending on size. Probably  log N.

To achieve parallel scalability HTreeMap is split to 16  segments,
each with separate read-write lock. ``ConcurrentHashMap`` in JDK 7 works similar
way. Number of segments (also called concurrency scale) is hard wired
into design and can not be changed.
Because all segments share underlying storage, concurrent scalability is not perfect.
Other option is to create each segment with separate storage. 

HTreeMap optionally supports entry expiration based on four criteria:
maximal map size, time-to-live since last modification and time-to-live
since last access. Expired entries are automatically removed. This
feature uses FIFO queue, each segment has independent expiration queue.
Priority per entry can not be set.

Parameters
----------

HTreeMap has number of parameters to tune its performance. Number of
segments (aka concurrency factor) is hard-coded to16 and can not be
changed. Other params can be set only when map is created and can not be
changed latter.

Most important are probably **serializers**. General serialization has
some guessing and overhead, so it always has better performance to use
more specific serializers. To specify key and value serializer use code
bellow. There are dozens ready to use serializers available as static
fields on ``Serializer`` interface:

.. code:: java

        HTreeMap<String, Long> map = db.createHashMap("map")
            .keySerializer(Serializer.STRING)
            .valueSerializer(Serializer.LONG)
            .makeOrGet()

HTreeMap is recommended for handling large key/values. In same cases you
may want to use compression. Enabling compression store-wide is not
always best, since constantly (de)compressing index tree has overhead.
Instead it is better to apply compression just to specific serializer on key or value.
This is done by using serializer wrapper:

.. code:: java

        HTreeMap<String, Long> map = db.createHashMap("map")
            .valueSerializer(new Serializer.CompressionWrapper(Serializer.STRING))
            .makeOrGet()
            
            TODO add Serializer.compressed() method?
            
            
Most hash maps uses 32bit hash generated by ``Object.hashCode()`` and check equality with ``Object.equals(other)``. 
However many classes do not implement those functions correctly, and inconsistent hashing is 
very bad for persistence, it could cause data loss.
In default configuration HTreeMap uses generic key serializer and relies on those methods as well,
however it throws an exception, if inconsitent hashing is detected. TODO exception name

If specialized Key Serializer is defined, HTreeMap relies on it to provide hash code and equality check 
for keys. For example ``Serializer.BYTE_ARRAY`` uses TODO link to ``java.util.Arrays.hashCode(byte[])``.
This way you can use primitive arrays directly as a key/value without a wrapper. 
Bypassing wrappers such as ``String`` improves performance: 

.. code:: java

        HTreeMap<byte[], Long> map = db.createHashMap("map")
            .keySerializer(Serializer.BYTE_ARRAY)
            .makeOrGet()

Other parameter is **size counter**. By default HTreeMap does not keep
track of its size, calling ``map.size()`` requires linear scan to count
all entries. You can enable size counter, in that case
``map.size()`` is instant, but there is some overhead on inserts.

.. code:: java

        HTreeMap<String, Long> map = db.createHashMap("map")
            .counterEnable()
            .makeOrGet()

And finally some sugar. There is **value creator**, a function to create
value if existing value is not found. Newly created value is inserted
into map. This way ``map.get(key)`` never returns null. This is mainly
useful for various generators and caches.

.. code:: java

        HTreeMap<String,Long> map = db.createHashMap("map")
                .valueCreator(new Fun.Function1<Long,String>() {
                    @Override public Long run(String o) {
                        return 1111L;
                    }
                })
                .makeOrGet();

or more readable version in Java 8:

.. code:: java

        HTreeMap<String,Long> map = db.createHashMap("map")
                .valueCreator((key)-> 1111L)
                .makeOrGet();

        // this way map.get() returns 1111L if no value is found
        map.get("aa"); // 1111L
        map.get("bb"); // 1111L

        // map now contains ["aa"->1111L, "bb"->1111L]

Entry expiration parameters
---------------------------

``HTreeMap`` offers optional entry expiration if some conditions are
met. Entry can expire if:

-  Number of entries in map would exceed maximal size

-  Entry exist in map longer time than expiration period is. The
   expiration period could be since last modification or since last read
   access.

-  Disk/memory space consumed by Map is bigger then some limit in GB.

There is shortcut in ``DBMaker`` to quickly use ``HTreeMap`` as off-heap
cache with memory size limit:

.. code:: java

        // Off-heap map with max size 16GB
        Map cache = DBMaker
            .newCacheDirect(16)

This equals to ``expireStoreSize`` param:

.. code:: java

        HTreeMap cache = db.createHashMap("cache")
            .expireStoreSize(128)
            .makeOrGet()

It is also possible to limit maximal size of map:

.. code:: java

        HTreeMap cache = db.createHashMap("cache")
            .expireMaxSize(128)
            .makeOrGet()

And finally you can set expiration time since last modification or since
last access.

.. code:: java

        // remove entries 1H after their last modification, or 10 minutes after last get()
        HTreeMap cache = db.createHashMap("cache")
             .expireAfterWrite(1, TimeUnit.HOURS)
             .expireAfterRead(10, TimeUnit.MINUTES)
             .makeOrGet()

TODO expiration counts are approximate. Map size can go slightly over limits for short period of time.

TODO disk space limit has issues. Investigate how it works and document

TODO expiration threads

Concurrent scalability
------------------------

HTreeMap scales concurrently by using 16 separate segment, each with its own ``ReadWriteLock``. 
Each segment has its own independent state, hash tree and also expiration queue.
But all segments still share underlying storage and are limited by its performance. 

There is option to shard HTreeMap. Each separate segment can get its own storage, so no shared
state exist between segments. This way one get linear concurrent scalability which corresponds
to 16 segments. TODO benchmarks.

Trade off in this case is higher memory consumption. There are 16 different stores, each with its own
memory allocator and unused blocks. TODO memory benchmarks. 
But each store can be compacted separately. TODO add compaction doc for this 

TODO example construct storage

Compared to BTreeMap
--------------------

`HTreeMap` has major advantage over `BTreeMap` with large keys. Unlike
BTreeMap it only stores hash codes in tree nodes. 
BTreeMap deserializes tree nodes together with their keys on each lookup. 
Simple ``BTreeMap.get(key)`` could deserialize houndreds of keys. 

TODO link to performance test, compare with BTreeMap

On other side HTreeMap has limited concurrency factor to 16, so with  
writes it wont scale over 4 CPU cores. It uses read-write locks, so read
operations are not affected. However in practice disk IO is more likely
to be bottleneck. TODO benchmarks

HTreeMap can be easily sharded by segments. For in-memory map it might have better 
concurent scalability. 

HTreeMap is simpler than BTreeMap. It has more predictable performance over long time
and does not get fragmented after frequent deletes.
HTreeMap also offers expiration. 
BTreeMap pays tax in some cases for its complex lock-free design.
