HTreeMap
=========
HTreeMap (aka HashMap) is one of `Map`s offered by MapDB. It has great performance with large keys. It also offers entry expiration if time-to-live or maximal size is exceeded.

HTreeMap is *segmented Hash Tree*. Most hash collections use an array for hash table, which requires copying all data when hash table is resized. HTreeMap uses auto-expanding 4 level tree, so it never needs resizing.

To support concurrency HTreeMap is split to 16 independent segments, each with separate read-write lock. `ConcurrentHashMap` works similar way. Number of segments (also called concurrency factor) is hard wired into design and can not be changed.

HTreeMap optionally supports entry expiration based on four criteria: maximal map size, time-to-live since last modification and time-to-live since last access. Expired entries are automatically removed. This feature uses FIFO queue, each segment has independent expiration queue. Priority per entry can not be set.

Parameters
----------------
HTreeMap has number of parameters to tune its performance. Number of segments (aka concurrency factor) is hard-coded to16 and can not be changed. Other params can be set  only when map is created and can not be changed latter.

Most important are probably **serializers**. General serialization has some guessing and overhead, so it always has better performance to use more specific serializers. To specify key and value serializer use code bellow. There are dozens ready to use serializers available as static fields on `Serializer` interface:

```java
    HTreeMap<String, Long> map = db.createHashMap("map")
        .keySerializer(Serializer.STRING)
        .valueSerializer(Serializer.LONG)
        .makeOrGet()
```

HTreeMap is recommended for handling large key/values. In same cases you may want to use compression. Enabling compression store-wide is not always best, since constantly (de)compressing index tree has overhead. Instead it is better to apply compression just to specific large key. This is done by using serializer wrapper:

```java
    HTreeMap<String, Long> map = db.createHashMap("map")
        .keySerializer(new Serializer.CompressionWrapper(Serializer.STRING))
        .makeOrGet()
```

Other useful parameter is **Hasher**. By default HTreeMap uses 32bit hash generated by `hashCode()`. Some classes just return memory pointer, which changes after serialization/deserialization, rendering it useless for persistence. Also it is not always necessary to calculate full hash of large objects (Strings), sometimes it is better to use weaker hash. So HTreeMap allows you to supply custom Hasher which will generate hash code  for keys and decide which keys are equal. This way  you can use primitive arrays as key without wrapper:

```java
    HTreeMap<byte[], Long> map = db.createHashMap("map")
        .keySerializer(Serializer.BYTE_ARRAY)
        .hasher(Hasher.BYTE_ARRAY)
        .makeOrGet()
```

Other parameter is **size counter**. By default HTreeMap does not keep track of its size, calling `map.size()` requires linear scan to count all entries. You can change it by enabling size counter, in that case `map.size()` is instant, but there is some overhead on inserts.

```java
    HTreeMap<String, Long> map = db.createHashMap("map")
        .counterEnable()
        .makeOrGet()
```

And finally some sugar. There is **value creator**, a function to create value if existing value is not found. Newly created value is inserted into map.  This way `map.get(key)` never returns null. This is mainly useful for various generators and caches.

```java
    HTreeMap<String,Long> map = db.createHashMap("map")
            .valueCreator(new Fun.Function1<Long,String>() {
                @Override public Long run(String o) {
                    return 1111L;
                }
            })
            .makeOrGet();
```

or more readable version in Java 8:

```java
    HTreeMap<String,Long> map = db.createHashMap("map")
            .valueCreator((key)-> 1111L)
            .makeOrGet();

    // this way map.get() returns 1111L if no value is found
    map.get("aa"); // 1111L
    map.get("bb"); // 1111L

    // map now contains ["aa"->1111L, "bb"->1111L]
```


Entry expiration parameters
----------------------------

`HTreeMap` offers optional entry expiration if some conditions are met. Entry can expire if:

 * Number of entries in map would exceed maximal size

 * Entry exist in map longer time than expiration period is. The expiration period could be since last modification or last read access.

 * Disk/memory space consumed by Map is bigger then some limit in GB.


There is shortcut in `DBMaker` to quickly use `HTreeMap` as off-heap cache with memory size limit:

```java
    // Off-heap map with max size 16GB
    Map cache = DBMaker
	    .newCacheDirect(16)
```

This equals to `expireStoreSize` param:

```java
    HTreeMap cache = db.createHashMap("cache")
        .expireStoreSize(128)
        .makeOrGet()
```

It is also possible to limit maximal size of map:

```java
    HTreeMap cache = db.createHashMap("cache")
        .expireMaxSize(128)
        .makeOrGet()
```

And finally you can set expiration time since last modification or since last access.

```java
    // remove all entries 1H after last modification, or 10 minutes after last get()
    HTreeMap cache = db.createHashMap("cache")
         .expireAfterWrite(1, TimeUnit.HOURS)
         .expireAfterRead(10, TimeUnit.MINUTES)
         .makeOrGet()
```


Compared to BTreeMap
--------------------
HTreeMap has one major advantage for using with large keys. Unlike BTreeMap it only stores hash codes in tree nodes. Each lookup on BTreeMap deserializes number of tree nodes together with their keys.

TODO link to performance test, compare with BTreeMap

On other side HTreeMap has limited concurrency factor to 16, so its writes wont scale over 4 CPU cores. It uses read-write locks, so read operations are not affected. However in practice disk IO is more likely to be bottleneck.
